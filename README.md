# Scalable Retail Analytics Pipeline on AWS

![Python](https://img.shields.io/badge/Python-3.10-blue)
![PySpark](https://img.shields.io/badge/PySpark-3.5-orange)
![AWS](https://img.shields.io/badge/AWS-EC2%20%7C%20S3%20%7C%20SageMaker-yellow)

## ğŸ¯ Project Overview

End-to-end Big Data analytics pipeline built on AWS cloud infrastructure to process and analyze 1M+ retail transactions. Leverages Apache Spark for distributed computing, AWS services for scalable storage and ML, and Power BI for business intelligence dashboards.

**Built as part of:** Big Data Applications Course (Indiana University, Fall 2025)

---

## ğŸš€ Key Technologies

**Big Data & Processing:**
- Apache Spark 3.5 / PySpark
- Distributed computing on AWS EC2
- ETL pipeline automation

**Cloud Infrastructure (AWS):**
- **S3:** Data Lake architecture (raw/processed separation)
- **EC2:** t2.micro instance (Ubuntu 22.04) for Spark processing
- **SageMaker Canvas:** No-code ML model training
- **IAM:** Role-based security for S3 access
- **Boto3:** AWS SDK for Python

**Analytics & Visualization:**
- Spark SQL for distributed queries
- Power BI for interactive dashboards
- Statistical aggregation and trend analysis

---

## ğŸ“Š Business Impact

âœ… **Processed 1,067,371 transaction records** across 38 countries (2009-2011)  
âœ… **Analyzed Â£14M+ in revenue**, identifying UK as dominant market (80%+ share)  
âœ… **Discovered 300% sales spike** in November for inventory optimization  
âœ… **Reduced analysis time** from manual Excel workflows (hours) â†’ automated Spark pipeline (minutes)  
âœ… **Identified top-selling products** driving 100K+ unit sales  

---

## ğŸ—ï¸ Architecture
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Raw CSV Data  â”‚
â”‚   (UCI Dataset) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       AWS S3 (Data Lake)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  raw_data/  â”‚  â”‚processed_data/â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     AWS EC2 (Ubuntu 22.04)          â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚   Apache Spark 3.5          â”‚   â”‚
â”‚   â”‚   - PySpark ETL Pipeline    â”‚   â”‚
â”‚   â”‚   - Data Cleaning           â”‚   â”‚
â”‚   â”‚   - Feature Engineering     â”‚   â”‚
â”‚   â”‚   - Aggregation & Metrics   â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚
           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  AWS SageMaker   â”‚  â”‚    Power BI     â”‚
â”‚     Canvas       â”‚  â”‚   Dashboard     â”‚
â”‚  (ML Prediction) â”‚  â”‚ (Visualization) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ Technical Implementation

### 1ï¸âƒ£ Data Ingestion & Storage
- **Dataset:** Online Retail II from UCI ML Repository (1.06M rows, 8 attributes)
- **Storage Pattern:** Download from S3 â†’ Process locally on EC2 â†’ Upload results to S3
- **Security:** IAM role-based authentication (no hardcoded API keys)

### 2ï¸âƒ£ ETL Pipeline (PySpark)

**Data Cleaning Steps:**
```python
# Remove cancellations (Invoice starting with 'C')
df_clean = df.filter(~col("Invoice").startswith("C"))

# Type casting and null handling
df_clean = df_clean.withColumn("Quantity", col("Quantity").cast("int")) \
                   .withColumn("Price", col("Price").cast("double")) \
                   .dropna(subset=['Description', 'Customer ID'])

# Feature engineering
df_processed = df_clean.withColumn("TotalLinePrice", 
                                   col("Quantity") * col("Price"))
```

**Result:** 800,000+ valid transactions after cleaning (75% of raw data)

### 3ï¸âƒ£ Business Metrics & Aggregation

**Key Queries Implemented:**
```python
# Top selling products
df_processed.groupBy("Description") \
    .agg(_sum("Quantity").alias("Total_Sold")) \
    .orderBy(desc("Total_Sold")).limit(5)

# Revenue by country
df_processed.groupBy("Country") \
    .agg(_sum("TotalLinePrice").alias("Total_Revenue")) \
    .orderBy(desc("Total_Revenue"))

# Monthly sales trends (seasonality analysis)
df_processed.groupBy("Year", "Month") \
    .agg(_sum("TotalLinePrice").alias("Sales")) \
    .orderBy("Year", "Month")
```

### 4ï¸âƒ£ Machine Learning (AWS SageMaker Canvas)
- **Model Type:** Regression (Quick Build)
- **Target Variable:** `TotalLinePrice` (transaction value prediction)
- **Key Finding:** `Quantity` identified as strongest predictor (aligns with retail logic)

### 5ï¸âƒ£ Visualization (Power BI)
- **Geospatial map** showing revenue distribution across 38 countries
- **Time-series trends** highlighting November sales spike (seasonal pattern)
- **Product ranking** bar chart for top 5 performing items
- **KPI cards** displaying total revenue, transaction count

**ğŸ“Š View Dashboard:** [Google Drive Link](https://drive.google.com/file/d/1KF3S7Xy0qlM-uMY9rnP_5KwRXbgw_k0q/view?usp=sharing)  
*(Download .pbix file to view in Power BI Desktop)*

---

## ğŸ“ˆ Key Insights Discovered

### Market Analysis
- **United Kingdom:** Â£14M+ revenue (80%+ of total sales)
- **International Growth Opportunity:** EIRE, Netherlands, Germany show potential but underserved

### Product Performance
- **Top Seller:** "WORLD WAR 2 GLIDERS ASSTD DESIGNS" (100K+ units)
- **Strategy:** Mix of low-cost high-volume novelty items + premium home decor

### Seasonality
- **November Spike:** 300% increase in sales (pre-Christmas shopping behavior)
- **Actionable:** Optimize inventory and staffing for Q4

### Customer Segmentation
- **Wholesale Focus:** Many customers are B2B wholesalers (bulk purchases)
- **Opportunity:** Develop targeted loyalty programs for top customers

---

## ğŸ–¼ï¸ Sample Outputs

### Spark Processing (Terminal Output)
```
--- 1. Ingesting Data from local_data.csv ---
Total Rows Loaded: 1067371

--- 2. Cleaning & Processing ---
Valid Clean Transactions: 801857

--- Aggregation Metrics ---
1. Top Selling Products:
+------------------------------------------+----------+
|Description                               |Total_Sold|
+------------------------------------------+----------+
|WORLD WAR 2 GLIDERS ASSTD DESIGNS         |102942    |
|JUMBO BAG RED RETROSPOT                   |88280     |
|ASSORTED COLOUR BIRD ORNAMENT             |81416     |
|WHITE HANGING HEART T-LIGHT HOLDER        |79819     |
|PACK OF 72 RETROSPOT CAKE CASES           |70988     |
+------------------------------------------+----------+

2. Revenue by Country:
+--------------+------------------+
|Country       |Total_Revenue     |
+--------------+------------------+
|United Kingdom|14382877.59       |
|EIRE          |789094.82         |
|Netherlands   |284861.33         |
|Germany       |281697.84         |
|France        |211892.41         |
+--------------+------------------+
```

### Power BI Dashboard Preview
![Dashboard](screenshots/powerbi_dashboard.png)
*Interactive dashboard showing geospatial revenue map, monthly trends, and product rankings*

---

## ğŸš¦ How to Run Locally

### Prerequisites
```bash
# System requirements
- Python 3.10+
- Java 17 (OpenJDK)
- 4GB+ RAM recommended

# Install dependencies
pip install -r requirements.txt
```

### Setup Steps
```bash
# 1. Clone repository
git clone https://github.com/yourusername/retail-analytics-aws.git
cd retail-analytics-aws

# 2. Download sample dataset
# Place CSV file in project root as 'local_data.csv'

# 3. Configure AWS credentials (if using S3)
aws configure
# Enter your AWS Access Key ID, Secret Key, and region

# 4. Run pipeline
python pipeline.py
```

### Expected Output
- Cleaned data saved to `processed_output/` directory
- Aggregated metrics printed to console
- (Optional) Processed data uploaded to S3 bucket

---

## ğŸ“ Project Structure
```
retail-analytics-aws/
â”‚
â”œâ”€â”€ README.md                 # This file
â”œâ”€â”€ pipeline.py               # Main ETL script (PySpark)
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ local_data.csv            # Sample dataset (not included - too large)
â”‚
â”œâ”€â”€ processed_output/         # Generated after running pipeline
â”‚   â””â”€â”€ final_data.csv        # Cleaned and processed transactions
â”‚
â”œâ”€â”€ screenshots/              # Visual documentation
â”‚   â”œâ”€â”€ powerbi_dashboard.png
â”‚   â”œâ”€â”€ spark_execution.png
â”‚   â””â”€â”€ sagemaker_model.png
â”‚
â””â”€â”€ docs/                     # Additional documentation
    â””â”€â”€ project-report.pdf    # Full technical report
```

---

## ğŸ§© Challenges & Solutions

### Challenge 1: S3A Connector Compatibility
**Problem:** `NumberFormatException: "60s"` when reading directly from S3 using `spark.read.csv("s3a://...")`  
**Root Cause:** Hadoop-AWS connector incompatibility with Java 21 on Ubuntu  
**Solution:** Implemented "Download-Process-Upload" pattern using Boto3 for reliable S3 interaction

### Challenge 2: Free Tier Memory Constraints
**Problem:** t2.micro instance (1GB RAM) caused `MemoryError` during package installation  
**Solution:** Used `pip install --no-cache-dir` and OpenJDK-headless to minimize memory footprint

### Challenge 3: Data Quality Issues
**Problem:** Negative quantities (cancellations) and null Customer IDs skewed metrics  
**Solution:** Implemented rigorous filtering logic to exclude invalid records (25% data reduction)

---

## ğŸ“š Dataset Information

**Source:** UCI Machine Learning Repository  
**Name:** Online Retail II Data Set  
**Period:** December 1, 2009 - December 9, 2011  
**Business:** UK-based online gift retailer (B2B and B2C)  

**Attributes:**
- `InvoiceNo`: Transaction ID (6-digit, 'C' prefix = cancellation)
- `StockCode`: Product ID (5-digit)
- `Description`: Product name
- `Quantity`: Items per transaction
- `InvoiceDate`: Timestamp
- `UnitPrice`: Price in GBP (Â£)
- `CustomerID`: Customer identifier (5-digit)
- `Country`: Customer location

**Citation:**  
Chen, D. (2015). *Online Retail II Data Set*. UCI Machine Learning Repository.  
https://archive.ics.uci.edu/ml/datasets/Online+Retail+II

---

## ğŸ“ Learning Outcomes

- Designed and deployed scalable cloud-based data pipelines on AWS
- Processed large-scale datasets using distributed computing (Apache Spark)
- Implemented ETL workflows with data quality checks and feature engineering
- Built predictive models using AWS SageMaker for business forecasting
- Created interactive dashboards for stakeholder communication
- Applied IAM security best practices for cloud resource access

---

## ğŸ”— Additional Resources

- **Full Project Report:** [View PDF](docs/project_report.pdf)
- **Power BI Dashboard:** [Download .pbix](https://drive.google.com/file/d/1KF3S7Xy0qlM-uMY9rnP_5KwRXbgw_k0q/view?usp=sharing)
- **Demo Video:** [Watch on Google Drive](https://drive.google.com/file/d/1m9lbA3doBeAkluqEgM88n3W_NJ8CEv33/view?usp=sharing)

---

## ğŸ‘¨â€ğŸ’» Author

**Siddhesh Pande**  
MS Data Science, Indiana University  
[LinkedIn](https://linkedin.com/in/siddhesh-pande) | [GitHub](https://github.com/sidpan19)

---

## ğŸ“ License

This project is for educational purposes. Dataset used under UCI ML Repository terms.

---

## ğŸ™ Acknowledgments

- **Course:** Big Data Applications (Indiana University)
- **Dataset:** UCI Machine Learning Repository
- **Cloud Credits:** AWS Educate Free Tier
